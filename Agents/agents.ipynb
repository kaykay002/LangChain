{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with multiple data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n"
     ]
    }
   ],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(wiki.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorDB with OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method VectorStore.as_retriever of <langchain_community.vectorstores.faiss.FAISS object at 0x000001A1DBE06270>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents, OllamaEmbeddings())\n",
    "retriever=vectordb.as_retriever\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARXIV Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(arxiv_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combining all the tools in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki, arxiv, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\Admin\\\\Desktop\\\\GUVI\\\\LangChain\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(),\n",
       " Tool(name='langsmith_search', description='Search for information about langsmith search', args_schema=<class 'langchain_core.tools.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x000001A194504FE0>, retriever=<bound method VectorStore.as_retriever of <langchain_community.vectorstores.faiss.FAISS object at 0x000001A1DBE06270>>, document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x000001A194505440>, retriever=<bound method VectorStore.as_retriever of <langchain_community.vectorstores.faiss.FAISS object at 0x000001A1DBE06270>>, document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#Environment variables loaded\n",
    "load_dotenv()\n",
    "\n",
    "#LangSmith Tracking \n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Ollama LLAMA2 LLM\n",
    "llm=Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt tempalate\n",
    "\n",
    "#from langchain import hub\n",
    "\n",
    "#prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "#prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating prompt & deploying Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Assuming wiki, arxiv, and retriever_tool are defined as Tool objects\n",
    "tools = [wiki, arxiv, retriever_tool]\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"agent_scratchpad\", \"tool_names\", \"tools\", \"user_input\"],\n",
    "    template=\"You have everything to respond to the user. {agent_scratchpad}.\\nYou have access to the following tools:{tools} {tool_names}.\\n\\nUse them to answer the user's query: {user_input}.\\n\\nPlease structure your response in the following format:\\nAction: [Your action description]\\nThought: [Your explanation or reasoning]\\nAction Input: [Additional information needed for the action]\"\n",
    ")\n",
    "\n",
    "\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"agent_scratchpad\", \"user_input\"],\n",
    "    template=\"You have everything to respond to the user. {user_input}{agent_scratchpad} \"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'user_input'], partial_variables={'tools': \"wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\nlangsmith_search(query: 'str', *, retriever: 'BaseRetriever' = <bound method VectorStore.as_retriever of <langchain_community.vectorstores.faiss.FAISS object at 0x000001A1DBE06270>>, document_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator: 'str' = '\\\\n\\\\n', callbacks: 'Callbacks' = None) -> 'str' - Search for information about langsmith search\", 'tool_names': 'wikipedia, arxiv, langsmith_search'}, template=\"You have everything to respond to the user. {agent_scratchpad}.\\nYou have access to the following tools:{tools} {tool_names}.\\n\\nUse them to answer the user's query: {user_input}.\\n\\nPlease structure your response in the following format:\\nAction: [Your action description]\\nThought: [Your explanation or reasoning]\\nAction Input: [Additional information needed for the action]\")\n",
       "| RunnableBinding(bound=Ollama(), kwargs={'stop': ['\\nObservation']})\n",
       "| ReActSingleInputOutputParser()"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent executer to run agent\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Action: Conduct a search on Wikipedia and Arxiv to gather information about open source LLMs.\n",
      "\n",
      "Thought: Open source LLMs are generally considered to be good because they allow for transparency, reproducibility, and collaboration in the development of AI models. By making the code and weights of these models available publicly, researchers can review and build upon each other's work, leading to faster progress and more innovative solutions. Additionally, open source LLMs can help to promote accountability and trustworthiness in AI research by allowing for independent auditing and verification of the models' performance.\n",
      "\n",
      "Action Input: Search queries for Wikipedia and Arxiv include:\n",
      "\n",
      "* \"Open source LLMs\" on Wikipedia\n",
      "* \"LLMs\" on Arxiv with filters set to \"Language Modeling\" and \"Open Source\"\n",
      "\n",
      "Expected Output:\n",
      "The search results from both sources should provide information about the benefits and challenges of open source LLMs, as well as examples of successful open source LLM projects. The results may also highlight any potential drawbacks or limitations of these models, such as the need for large amounts of training data or the potential for bias in the training process.\u001b[0mConduct a search on Wikipedia and Arxiv to gather information about open source LLMs.\n",
      "\n",
      "Thought: Open source LLMs are generally considered to be good because they allow for transparency, reproducibility, and collaboration in the development of AI models. By making the code and weights of these models available publicly, researchers can review and build upon each other's work, leading to faster progress and more innovative solutions. Additionally, open source LLMs can help to promote accountability and trustworthiness in AI research by allowing for independent auditing and verification of the models' performance. is not a valid tool, try one of [wikipedia, arxiv, langsmith_search].\u001b[32;1m\u001b[1;3mAction: Conduct a search on Wikipedia and Arxiv to gather information about open source LLMs.\n",
      "\n",
      "Thought: Open source LLMs are generally considered to be good because they allow for transparency, reproducibility, and collaboration in the development of AI models. By making the code and weights of these models available publicly, researchers can review and build upon each other's work, leading to faster progress and more innovative solutions. Additionally, open source LLMs can help to promote accountability and trustworthiness in AI research by allowing for independent auditing and verification of the models' performance.\n",
      "\n",
      "Action Input: Search queries for Wikipedia and Arxiv include:\n",
      "\n",
      "* \"Open source LLMs\" on Wikipedia\n",
      "* \"LLMs\" on Arxiv with filters set to \"Language Modeling\" and \"Open Source\"\n",
      "\n",
      "Expected Output: The search results from both sources should provide information about the benefits and challenges of open source LLMs, as well as examples of successful open source LLM projects. The results may also highlight any potential drawbacks or limitations of these models, such as the need for large amounts of training data or the potential for bias in the training process.\u001b[0mConduct a search on Wikipedia and Arxiv to gather information about open source LLMs.\n",
      "\n",
      "Thought: Open source LLMs are generally considered to be good because they allow for transparency, reproducibility, and collaboration in the development of AI models. By making the code and weights of these models available publicly, researchers can review and build upon each other's work, leading to faster progress and more innovative solutions. Additionally, open source LLMs can help to promote accountability and trustworthiness in AI research by allowing for independent auditing and verification of the models' performance. is not a valid tool, try one of [wikipedia, arxiv, langsmith_search]."
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\"user_input\": \"Open source LLMs are good? \", \"agent_scratchpad\": \"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
